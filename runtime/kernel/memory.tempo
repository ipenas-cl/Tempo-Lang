// â•”â•â•â•â•â•â•¦â•â•â•â•â•â•¦â•â•â•â•â•â•—
// â•‘ ðŸ›¡ï¸  â•‘ âš–ï¸  â•‘ âš¡  â•‘
// â•‘  C  â•‘  E  â•‘  G  â•‘
// â•šâ•â•â•â•â•â•©â•â•â•â•â•â•©â•â•â•â•â•â•
// â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
// â•‘ wcet [Tâˆž] bound â•‘
// â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// Author: Ignacio PeÃ±a SepÃºlveda
// Date: June 25, 2025

// AtomicOS Physical Memory Manager
// Manages physical memory allocation using a bitmap allocator
//
// Author: Ignacio PeÃ±a SepÃºlveda
// Date: June 25, 2025
//
// Deterministic memory allocation with bounded allocation time
// All standard library functions are globally available in Tempo

const PAGE_SIZE = 4096
const MEMORY_START = 0x100000  // Start after 1MB (kernel loaded here)
const MEMORY_END = 0x1000000   // 16MB total memory for now

// Bitmap for tracking free/used pages
// Each bit represents one 4KB page
var memory_bitmap: [2048]u8  // 2048 bytes * 8 bits = 16384 pages = 64MB coverage

// Track memory statistics
var total_pages: u32 = 0
var used_pages: u32 = 0
var free_pages: u32 = 0

// Initialize the physical memory manager
func memory_init() {
    // Calculate total pages
    total_pages = (MEMORY_END - MEMORY_START) / PAGE_SIZE
    
    // Mark all pages as free initially
    for i in 0..2048 {
        memory_bitmap[i] = 0
    }
    
    // Mark kernel pages as used (first 1MB)
    // Assuming kernel takes up to 256KB after the 1MB mark
    let kernel_pages = 64  // 256KB / 4KB
    for i in 0..kernel_pages {
        mark_page_used(i)
    }
    
    // Update statistics
    used_pages = kernel_pages
    free_pages = total_pages - used_pages
}

// Allocate a physical page with deterministic behavior
func allocate_page() -> u32 {
    // Deterministic first-fit allocation with bounded search time
    let max_search = min(total_pages, 1024)  // Bound search to ensure WCET
    
    // Always start from the same position for determinism
    static let next_search_start: u32 = 0
    
    // Search from last allocation point (deterministic pattern)
    for offset in 0..max_search {
        let i = (next_search_start + offset) % total_pages
        if is_page_free(i) {
            mark_page_used(i)
            used_pages += 1
            free_pages -= 1
            
            // Update search position for next allocation
            next_search_start = (i + 1) % total_pages
            
            return MEMORY_START + (i * PAGE_SIZE)
        }
    }
    
    // If no page found in bounded search, do emergency compaction
    if free_pages > 0 {
        // Deterministic compaction would go here
        // For now, return failure
    }
    
    // Out of memory
    return 0
}

// Free a physical page
func free_page(addr: u32) {
    if addr < MEMORY_START || addr >= MEMORY_END {
        return  // Invalid address
    }
    
    let page_index = (addr - MEMORY_START) / PAGE_SIZE
    if !is_page_free(page_index) {
        mark_page_free(page_index)
        used_pages -= 1
        free_pages += 1
    }
}

// Check if a page is free
func is_page_free(page: u32) -> bool {
    let byte_index = page / 8
    let bit_index = page % 8
    return (memory_bitmap[byte_index] & (1 << bit_index)) == 0
}

// Mark a page as used
func mark_page_used(page: u32) {
    let byte_index = page / 8
    let bit_index = page % 8
    memory_bitmap[byte_index] |= (1 << bit_index)
}

// Mark a page as free
func mark_page_free(page: u32) {
    let byte_index = page / 8
    let bit_index = page % 8
    memory_bitmap[byte_index] &= ~(1 << bit_index)
}

// Get memory statistics
func get_memory_stats() -> (u32, u32, u32) {
    return (total_pages * PAGE_SIZE, used_pages * PAGE_SIZE, free_pages * PAGE_SIZE)
}

// Deterministic SLAB allocator for kernel objects
const SLAB_SIZES = [32, 64, 128, 256, 512, 1024, 2048, 4096]
const NUM_SLAB_SIZES = 8

struct SlabCache {
    size: u32,
    free_list: *SlabObject,
    page_list: *SlabPage,
    objects_per_page: u32,
    total_objects: u32,
    free_objects: u32,
}

struct SlabObject {
    next: *SlabObject,
}

struct SlabPage {
    next: *SlabPage,
    base_addr: u32,
    bitmap: u32,  // Track which objects are free
}

var slab_caches: [NUM_SLAB_SIZES]SlabCache

// Initialize SLAB allocator for deterministic small allocations
func slab_init() {
    for i in 0..NUM_SLAB_SIZES {
        slab_caches[i] = SlabCache{
            size: SLAB_SIZES[i],
            free_list: null,
            page_list: null,
            objects_per_page: PAGE_SIZE / SLAB_SIZES[i],
            total_objects: 0,
            free_objects: 0,
        }
    }
}

// Allocate object with deterministic behavior and bounded time
func slab_alloc(size: u32) -> *void {
    // Find appropriate slab size (deterministic)
    let slab_index = 0u32
    for i in 0..NUM_SLAB_SIZES {
        if size <= SLAB_SIZES[i] {
            slab_index = i
            break
        }
    }
    
    if slab_index >= NUM_SLAB_SIZES {
        return null  // Size too large for slab allocator
    }
    
    let cache = &slab_caches[slab_index]
    
    // Fast path: use free list
    if cache.free_list != null {
        let obj = cache.free_list
        cache.free_list = obj.next
        cache.free_objects -= 1
        return obj as *void
    }
    
    // Slow path: allocate new page (bounded operation)
    let page_addr = allocate_page()
    if page_addr == 0 {
        return null  // Out of memory
    }
    
    // Initialize new slab page
    let page = page_addr as *SlabPage
    page.next = cache.page_list
    page.base_addr = page_addr + sizeof(SlabPage)
    page.bitmap = 0xFFFFFFFF  // All objects initially free
    cache.page_list = page
    
    // Add all new objects to free list
    let obj_size = cache.size
    let obj_base = page.base_addr
    for i in 0..cache.objects_per_page {
        let obj = (obj_base + i * obj_size) as *SlabObject
        obj.next = cache.free_list
        cache.free_list = obj
    }
    
    cache.total_objects += cache.objects_per_page
    cache.free_objects += cache.objects_per_page
    
    // Allocate from newly created free list
    return slab_alloc(size)
}

// Free slab object with O(1) deterministic behavior
func slab_free(ptr: *void, size: u32) {
    // Find appropriate slab cache
    let slab_index = 0u32
    for i in 0..NUM_SLAB_SIZES {
        if size <= SLAB_SIZES[i] {
            slab_index = i
            break
        }
    }
    
    if slab_index >= NUM_SLAB_SIZES {
        return  // Invalid size
    }
    
    let cache = &slab_caches[slab_index]
    let obj = ptr as *SlabObject
    
    // Add to free list (O(1) operation)
    obj.next = cache.free_list
    cache.free_list = obj
    cache.free_objects += 1
}

// Helper function for bounded operations
func min(a: u32, b: u32) -> u32 {
    if a < b { return a } else { return b }
}